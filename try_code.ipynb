{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_API_KEY=\"AIzaSyARTJ3FH23kc-71fiNvS8Yiqq34l5mJRKo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyARTJ3FH23kc-71fiNvS8Yiqq34l5mJRKo\n"
     ]
    }
   ],
   "source": [
    "print(GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import re\n",
    "genai.configure(api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_desc_code_from_response(text: str):\n",
    "    \"\"\"\n",
    "    Extracts the description and code snippets from the input text.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text containing descriptions and code blocks.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list with the description as the first value and the code snippets as the second value.\n",
    "    \"\"\"\n",
    "    # Regex pattern to match code blocks\n",
    "    code_pattern = r\"```[\\s\\S]*?```\"\n",
    "    \n",
    "    # Extract all code blocks\n",
    "    code_snippets = re.findall(code_pattern, text)\n",
    "    \n",
    "    # Remove code blocks from the text to get the description\n",
    "    description = re.sub(code_pattern, \"\", text).strip()\n",
    "    \n",
    "    # Remove ``` markers from code snippets\n",
    "    cleaned_code_snippets = [snippet[6:-3].strip() for snippet in code_snippets]\n",
    "    \n",
    "    return [description, cleaned_code_snippets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ans_from_LLM(prompt):\n",
    "    model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "    response = model.generate_content(prompt)\n",
    "    desc, code = get_desc_code_from_response(response.text)\n",
    "    print(desc)\n",
    "    print(\"---------\")\n",
    "    print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"code for a react h1 that tells hell world\"\n",
    "get_ans_from_LLM(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT: An error occurred: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set your OpenAI API key\n",
    "api_key = \"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\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "def chat_with_gpt(prompt):\n",
    "    try:\n",
    "        # Send a request to the ChatGPT API\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",  # Use \"gpt-4\" if you have access\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a code generation of react components with inline css\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            # max_tokens=150,  # Adjust the response length as needed\n",
    "            # temperature=0.7  # Adjust creativity level\n",
    "        )\n",
    "        # Extract and return the assistant's reply\n",
    "        return response['choices'][0]['message']['content'].strip()\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    user_prompt = input(\"Enter your prompt: \")\n",
    "    reply = chat_with_gpt(user_prompt)\n",
    "    print(f\"ChatGPT: {reply}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
